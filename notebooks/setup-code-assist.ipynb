{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up local AI code assist\n",
    "\n",
    "I have been using a local llama3 LLM with ollama and the continue vs code extension with great results so far.\n",
    "\n",
    "- install pixi\n",
    "- install ollama and llms\n",
    "- start ollama with llama3\n",
    "- install vs code extension\n",
    "- configure continue extension to use ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install pixi\n",
    "\n",
    "We use pixi as a python manager, virtual environment, package manager and task runner all in one.\n",
    "Install it below.  If on windows, make sure you have winget installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "from subprocess import call\n",
    "\n",
    "uname = platform.uname()\n",
    "if uname.system == 'Windows':\n",
    "   retcode = call([\"where\", \"pixi\"])\n",
    "   if retcode != 0:\n",
    "      print(\"installing pixi\")\n",
    "      !winget install prefix-dev.pixi\n",
    "   else:\n",
    "      print(\"pixi is installed\")\n",
    "else:\n",
    "   retcode = call([\"which\", \"pixi\"])\n",
    "   if retcode != 0:\n",
    "      print(\"installing pixi\")\n",
    "      !curl -fsSL https://pixi.sh/install.sh | bash\n",
    "   else:\n",
    "      print(\"pixi is installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install ollama and llms\n",
    "\n",
    "We already have some pixi tasks defined, so we will run them to install the ollama runner and\n",
    "the LLMs we will use for code assisstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if uname.system == \"Windows\":\n",
    "    retcode = call([\"where\", \"ollama\"])\n",
    "    if retcode!= 0:\n",
    "        print(\"installing ollama\")\n",
    "        !winget install ollama\n",
    "    else:\n",
    "        print(\"ollama is installed\")\n",
    "else:\n",
    "    retcode = call([\"which\", \"ollama\"])\n",
    "    if retcode!= 0:\n",
    "        print(\"installing ollama\")\n",
    "        !pixi run ollama-install\n",
    "    else:\n",
    "        print(\"ollama is installed\")\n",
    "!pixi run ollama-pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start ollama with llama3\n",
    "\n",
    "We need to have ollama start llama3:8b so that the vscode extension can send messages to it.  Instead of running it in a cell in the notebook, run this in your shell instead\n",
    "\n",
    "```shell\n",
    "ollama run llama3:8b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install vs code extension\n",
    "\n",
    "Next we will install the vs code extension that allows us to hook into the LLM's we installed\n",
    "through ollama.  Again, we have a pixi task to help us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pixi run vscode-ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure continue extension \n",
    "\n",
    "Finally, we need to configure the continue extension so that it uses the ollama runner and the LLMs we installed above.\n",
    "\n",
    "Click on the gear icon in the bottom right corner of the view and select \"Configure\".  In the \n",
    "editor that pops up, enter the following:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"models\": [\n",
    "    {\n",
    "      \"title\": \"Llama3-8b\",\n",
    "      \"model\": \"llama3:8b\",\n",
    "      \"contextLength\": 4096,\n",
    "      \"provider\": \"ollama\"\n",
    "    }\n",
    "  ],\n",
    "  \"tabAutoCompleteModel\": {\n",
    "    \"title\": \"Tab Complete Model\",\n",
    "    \"provider\": \"ollama\",\n",
    "    \"model\": \"starcoder2:3b\"\n",
    "  },\n",
    "  \"customCommands\": [\n",
    "    {\n",
    "      \"name\": \"test\",\n",
    "      \"prompt\": \"{{{ input }}}\\n\\nWrite a comprehensive set of unit tests for the selected code. It should setup, run tests that check for correctness including important edge cases, and teardown. Ensure that the tests are complete and sophisticated. Give the tests just as chat output, don't edit any file.\",\n",
    "      \"description\": \"Write unit tests for highlighted code\"\n",
    "    }\n",
    "  ],\n",
    "  \"allowAnonymousTelemetry\": false\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Code Assist examples\n",
    "\n",
    "Here are a few examples of what the AI code assist can do for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer command from context\n",
    "\n",
    "Here's an example of some text in a comment, and the AI determines the command that should be run.\n",
    "\n",
    "![infer-command](./resources/complete_apt_install.png \"Infer command\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code complete based on definitions\n",
    "\n",
    "Here's an example where the AI knows what a data type is.  I started to type in \"The participant\"\n",
    "and the AI predicted what code I would want to write.\n",
    "\n",
    "![complete-on-def](./resources/complete_participant.png \"Definition Completion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict based on earlier code\n",
    "\n",
    "Here's an example where I started a new cell in the jupyter notebook.  Noticed that in\n",
    "the previous cell, I had a list of steps to run.  In the next cell, based on the code\n",
    "I had written for that cell, it predicted the command based on the first bullet in the\n",
    "earlier cell.\n",
    "\n",
    "![earlier-code](./resources/complete_pip_install.png \"Earlier Code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context aware completion\n",
    "\n",
    "This example shows that not only did it know what code I would write, but it also knew that\n",
    "the key `channel` was related to how the event was sent.  Note the suggested code was \"the channel used to contact the participant\".  The AI figured out that _channel_ was some kind of medium that\n",
    "the message could be delivered through on its own.\n",
    "\n",
    "![context-aware](./resources/complete_code.png  \"Context Aware\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
