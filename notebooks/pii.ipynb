{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    device_map=\"auto\",\n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": torch.float16,\n",
    "        \"quantization_config\": {\"load_in_4bit\": True},\n",
    "        \"low_cpu_mem_usage\": True,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from tab_exp.tab import generate_synth_data, PIIData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_train = generate_synth_data(samples=1000, output=\"samples_train\", clean=True, debug=True)\n",
    "ds_train = load_dataset(\"json\", data_files=sd_train[\"combined_path\"], split=\"train\")\n",
    "\n",
    "sd_test = generate_synth_data(samples=300, output=\"samples_test\", clean=True, debug=True)\n",
    "ds_test = load_dataset(\"json\", data_files=sd_test[\"combined_path\"])\n",
    "\n",
    "# sd_validate = generate_synth_data(samples=100, output=\"samp  les_validate\", clean=True, debug=True)\n",
    "# ds_validate = load_dataset(\"json\", data_files=sd_validate[\"combined_path\"], split=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the text in the dataset to numbers\n",
    "from transformers import DataCollatorWithPadding, TrainingArguments\n",
    "\n",
    "def tokenize_fn(data: PIIData):\n",
    "    return tokenizer(data['text'], truncation=True, padding=True)\n",
    "tokened_train_ds = ds_train.map(tokenize_fn)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "PII project \n",
    "\n",
    "- in the tab module:\n",
    "    - for each field, create the text and a label of anonymized, original\n",
    "    - create one an example for anonymized and original each\n",
    "    - Create a Dataset from this sequence\n",
    "- pass the dataset to the model\n",
    "- follow the [directions here to use ORPO](https://huggingface.co/blog/mlabonne/orpo-llama-3)\n",
    "- Run some experiments with different hyperparams\n",
    "    - Look into plotting the results with plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"user_id\": 1234,\\n    \"another_val\": \"something\"\\n}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tiktoken as tt\n",
    "enc_name = tt.encoding_name_for_model(\"gpt-4o\")\n",
    "enc = tt.get_encoding(enc_name)\n",
    "\n",
    "toks = enc.encode('''{\n",
    "    \"user_id\": 1234,\n",
    "    \"another_val\": \"something\"\n",
    "}''')\n",
    "enc.decode(toks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
